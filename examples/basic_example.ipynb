{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from openai import OpenAI\n",
    "from prompt_optimizer import PipelineOptimizer, llm_node, OpenAIAdapter\n",
    "\n",
    "# Basic steps:\n",
    "# 1) Add a `llm_node` decorator to an LLM function\n",
    "# 2) Create an evaluation template\n",
    "# 3) Define your \"training\" data\n",
    "# 4) Set up the optimizer\n",
    "# 5) Check the results!\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "system_prompt = \"you are a helpful assistent\"\n",
    "\n",
    "# Add a `llm_node` decorator around a function which takes a prompt to be optimised\n",
    "# the input should be a component to be optimised (`system_prompt`` in this case)\n",
    "@llm_node(system_prompt=system_prompt)\n",
    "def answer_query(query: str, system_prompt: str = system_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Define a template for evaluating the final answer\n",
    "# you may use {pipeline_output} and any other custom key word arguments (kwargs)\n",
    "exact_match_evaluator = dedent(\n",
    "    \"\"\"\n",
    "    Your task is to judge the quality if the response given by an AI assistent.\n",
    "    Below are the <question>, <assistent_response> and <expected_answer>.\n",
    "    A correct answer would be an exact string match between the <assistent_response> and the\n",
    "    <expected_answer>\n",
    "\n",
    "    <question>{query}</question>\n",
    "    <assistent_response>{pipeline_ouput}</assistent_response>\n",
    "    <expected_answer>{golden_answer}</expected_answer>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define your dataset, this could have any number of items in the dictionary\n",
    "# and contain any number of examples\n",
    "data = [{\n",
    "    \"query\": \"what is the capital of France?\",\n",
    "    \"golden_answer\": \"<answer>Paris</answer>\"\n",
    "}]\n",
    "\n",
    "# Instantiate an optimizer and pass in an `LLMCallable`\n",
    "# (in this case using the OpenAIAdapter)\n",
    "llm = OpenAIAdapter(client)\n",
    "optimizer = PipelineOptimizer(llm)\n",
    "\n",
    "# Optimize\n",
    "optimizer.optimize(\n",
    "    iterations=1,\n",
    "    pipeline_func=answer_query,\n",
    "    evaluation_template=exact_match_evaluator,\n",
    "    data=data,\n",
    ")\n",
    "\n",
    "# Check the results\n",
    "result = answer_query(\"what is the capital of England?\").value\n",
    "\n",
    "print(result)\n",
    "# ---- expected answer: ----\n",
    "# <answer>London</answer>\n",
    "\n",
    "print(optimizer.get_prompt_info())\n",
    "# ---- expected answer: ----\n",
    "# Node: `answer_query`\n",
    "#  system_prompt: Provide the answer strictly in the required format, enclosing your response within <answer></answer> tags. Ensure that the content is clear, concise, and directly addresses the question while maintaining a helpful tone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
